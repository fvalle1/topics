{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The watermark extension is already loaded. To reload it, use:\n",
      "  %reload_ext watermark\n",
      "Filippo_Valle \n",
      "last updated: Tue Jun 30 2020 \n",
      "\n",
      "CPython 3.7.6\n",
      "IPython 7.15.0\n",
      "\n",
      "pandas 1.0.4\n",
      "numpy 1.18.5\n",
      "textwrap unknown\n",
      "matplotlib 3.2.1\n",
      "sklearn 0.0\n",
      "gseapy 0.9.18\n",
      "\n",
      "compiler   : GCC 7.5.0\n",
      "system     : Linux\n",
      "release    : 4.19.76-linuxkit\n",
      "machine    : x86_64\n",
      "processor  : x86_64\n",
      "CPU cores  : 2\n",
      "interpreter: 64bit\n",
      "Git hash   : 728c5fcb2ae65fb2d06e3b61b8b167d388b13f95\n",
      "Git repo   : git@github.com:fvalle1/topics.git\n",
      "Git branch : develop\n",
      "watermark 2.0.2\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -v -m  -u -n -p pandas,numpy,textwrap,matplotlib,sklearn,gseapy -a Filippo_Valle -g -r -b -w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from textwrap import wrap\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import metrics\n",
    "import matplotlib.ticker as mticker\n",
    "import sys, os\n",
    "from hsbmpy import plot_topic_size, get_max_available_L\n",
    "from hypergeom import parameters_for_hypergeometric, build_map, plot_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory=\"/home/jovyan/work/phd/datasets/cancers/breast\"\n",
    "os.chdir(directory)\n",
    "sys.path.append('/home/jovyan/work/phd/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = get_max_available_L(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"mainTable.csv\", index_col=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geneontology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geneontology import get_ontology_df, ensg_to_symbol\n",
    "from tableanalyser import get_symbol\n",
    "import gseapy as gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=L-1\n",
    "print(f\"level {l}\")\n",
    "algorithm = \"topsbm\"\n",
    "df_topics = pd.read_csv(f\"{directory}/{algorithm}/{algorithm}_level_{l}_topics.csv\")\n",
    "df_topics_smooth = pd.read_csv(f\"{directory}/{algorithm}/{algorithm}_level_{l}_word-dist.csv\",index_col=0)\n",
    "df_topics_smooth.index = [g[:15] for g in df_topics_smooth.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_over_thr(topic_name, q=0.75):\n",
    "    topic = df_topics_smooth[topic_name]\n",
    "    topic = topic[topic>0]\n",
    "    topic = topic[topic>topic.quantile(q=q)]\n",
    "    return topic.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_symbols= pd.read_csv(\"https://www.genenames.org/cgi-bin/download/custom?col=gd_hgnc_id&col=gd_app_sym&col=gd_pub_ensembl_id&col=md_ensembl_id&col=md_eg_id&status=Approved&status=Entry%20Withdrawn&hgnc_dbtag=on&order_by=gd_app_sym_sort&format=text&submit=submit\", index_col=[0], sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sea():\n",
    "    for g in df_topics.values.ravel()[[str(s)!='nan' for s in df_topics.values.ravel()]]:\n",
    "        yield get_symbol(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"gback.txt\",'w') as f:\n",
    "    list(map(lambda x: f.writelines(x+'\\n')if len(x)>1 else None, get_sea()))\n",
    "    \n",
    "with open(\"gback_ensg.txt\",'w') as f:\n",
    "    list(map(lambda x: f.writelines(x[:15]+'\\n')if len(x)>1 else None, df_topics.values.ravel()[[str(s)!='nan' for s in df_topics.values.ravel()]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.get_library_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.gsea-msigdb.org/gsea/downloads.jsp\n",
    "gene_sets = ['GO_Molecular_Function_2018',\n",
    "             'GO_Biological_Process_2018',\n",
    "             'GO_Cellular_Component_2018',\n",
    "             'Human_Phenotype_Ontology',\n",
    "             'WikiPathways_2019_Human',\n",
    "             '/home/jovyan/work/phd/MSigDB/c1.all.v7.1.symbols.gmt',\n",
    "             '/home/jovyan/work/phd/MSigDB/c2.all.v7.1.symbols.gmt',\n",
    "             '/home/jovyan/work/phd/MSigDB/c3.all.v7.1.symbols.gmt',\n",
    "             '/home/jovyan/work/phd/MSigDB/c4.all.v7.1.symbols.gmt',\n",
    "             '/home/jovyan/work/phd/MSigDB/c5.all.v7.1.symbols.gmt',\n",
    "             '/home/jovyan/work/phd/MSigDB/c6.all.v7.1.symbols.gmt',\n",
    "             '/home/jovyan/work/phd/MSigDB/c7.all.v7.1.symbols.gmt',\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshhold = 5e-1\n",
    "cutoff = 5e-1\n",
    "background = len([g for g in get_sea()])\n",
    "os.system(\"mkdir -p gsea\")\n",
    "for itopic,topic in enumerate(df_topics.columns):\n",
    "    try:\n",
    "        enriched_topic = pd.read_csv(\"gsea/gsea_level_%d_topic_%d.csv\"%(l,itopic+1), index_col=[0])\n",
    "        print(topic)\n",
    "    except:\n",
    "        try:\n",
    "            gene_list = ensg_to_symbol(df_topics.loc[:,topic].dropna().values)\n",
    "            #gene_list = ensg_to_symbol(get_topic_over_thr(topic).index)\n",
    "            print(topic)\n",
    "            enriched_topic = get_ontology_df(gene_list, cutoff=cutoff, threshhold = threshhold, gene_sets = gene_sets, background=background)\n",
    "            enriched_topic = enriched_topic.sort_values(by=['Adjusted P-value'], ascending=True)[:20]\n",
    "            enriched_topic.to_csv(\"gsea/gsea_level_%d_topic_%d.csv\"%(l,itopic+1))\n",
    "        except:\n",
    "            print(*sys.exc_info())\n",
    "            continue\n",
    "    print(enriched_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_pvalues = []\n",
    "topic_gos = []\n",
    "for itopic,topic in enumerate(df_topics.columns):\n",
    "    try:\n",
    "        enriched_topic = pd.read_csv(\"gsea/gsea_level_%d_topic_%d.csv\"%(l,itopic+1))\n",
    "        if len(enriched_topic.index) >0:\n",
    "            p_val = np.sort(enriched_topic['Adjusted P-value'])[0]\n",
    "            topic_pvalues.append(-np.log10(p_val))\n",
    "            for goc in enriched_topic['Gene_set'][:10].unique():\n",
    "                topic_gos.append(goc)\n",
    "        print(topic)\n",
    "    except:\n",
    "        print(\"error\", sys.exc_info()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18,15))\n",
    "x = np.arange(1,1+len(topic_pvalues))\n",
    "c, _, _ = plt.hist(topic_pvalues, histtype='step', lw=20, bins=45, color=\"gray\")\n",
    "plt.vlines(-np.log10(0.05),0,np.max(c)*1.1, color=\"red\", ls='--', lw=10, label=\"$\\\\alpha=0.05$\")\n",
    "plt.xlabel('-log(P-value)', fontsize=35)\n",
    "plt.ylabel(\"number of topics\", fontsize=35)\n",
    "#plt.ylim(0,0.055)\n",
    "#plt.yscale('log')\n",
    "plt.legend(fontsize=35)\n",
    "plt.tick_params(which=\"both\",labelsize=35)\n",
    "fig.savefig(\"%s/pvaluescrosstopic(%d).pdf\"%(directory,l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18,20))\n",
    "gos, goscounts = np.unique(topic_gos, return_counts=True)\n",
    "plt.barh([\"\\n\".join(wrap(str(l).replace('_',' '),20)) for l in gos], goscounts)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.tick_params(which=\"both\",labelsize=35)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig(\"%s/pvaluecategories(%d).pdf\"%(directory,l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hypergeometric operlaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import hypergeom\n",
    "from sklearn.metrics import v_measure_score\n",
    "import seaborn as sns\n",
    "sns.set_context('paper')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib, hypergeom\n",
    "importlib.reload(hypergeom)\n",
    "from hypergeom import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsbm_list_topics = pd.read_csv(\"topsbm/topsbm_level_3_topics.csv\")\n",
    "gene_list = hsbm_list_topics.values.ravel().astype(str)\n",
    "gene_list = list(map(lambda g: g[:15],filter(lambda g: g!=\"nan\", gene_list)))\n",
    "hsbm_list=pd.Series(index=[g[:15] for g in gene_list], dtype=str)\n",
    "for topic in hsbm_list_topics.columns:\n",
    "    hsbm_list[[g[:15] for g in hsbm_list_topics[topic].dropna()]]=topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsbm_list_topics = pd.read_csv(\"topsbm-log/topsbm-log_level_3_topics.csv\")\n",
    "gene_list = hsbm_list_topics.values.ravel().astype(str)\n",
    "gene_list = list(map(lambda g: g[:15],filter(lambda g: g!=\"nan\", gene_list)))\n",
    "hsbm_log_list=pd.Series(index=[g[:15] for g in gene_list], dtype=str)\n",
    "for topic in hsbm_list_topics.columns:\n",
    "    hsbm_log_list[[g[:15] for g in hsbm_list_topics[topic].dropna()]]=topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wgcna_list_topics = pd.read_csv(\"wgcna/wgcna_level_0_topics.csv\")\n",
    "gene_list = wgcna_list_topics.values.ravel().astype(str)\n",
    "gene_list = list(map(lambda g: g[:15],filter(lambda g: g!=\"nan\", gene_list)))\n",
    "wgcna_list=pd.Series(index=np.unique([g[:15] for g in gene_list]), dtype=str)\n",
    "for topic in wgcna_list_topics.columns:\n",
    "    wgcna_list[np.unique([g[:15] for g in wgcna_list_topics[topic].dropna()])]=topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm_list_topics = pd.read_csv(\"tm/tm_level_0_topics.csv\")\n",
    "gene_list = tm_list_topics.values.ravel().astype(str)\n",
    "gene_list = list(map(lambda g: g[:15],filter(lambda g: g!=\"nan\", gene_list)))\n",
    "tm_list=pd.Series(index=np.unique([g[:15] for g in gene_list]), dtype=str)\n",
    "for topic in tm_list_topics.columns:\n",
    "    tm_list[np.unique([g[:15] for g in tm_list_topics[topic].dropna()])]=topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_list_topics = pd.read_csv(\"lda/lda_level_1_topics.csv\")\n",
    "gene_list = lda_list_topics.values.ravel().astype(str)\n",
    "gene_list = list(map(lambda g: g[:15],filter(lambda g: g!=\"nan\", gene_list)))\n",
    "lda_list=pd.Series(index=[g[:15] for g in gene_list], dtype=str)\n",
    "for topic in lda_list_topics.columns:\n",
    "    lda_list[lda_list.index.isin([g[:15] for g in lda_list_topics[topic].dropna()])]=topic\n",
    "lda_list=lda_list.reset_index().drop_duplicates(\"index\").set_index(\"index\")\n",
    "lda_list=pd.Series(index=lda_list.index, data=lda_list.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(first_name, last_name):\n",
    "    list_1 = globals()[f\"{first_name}_list\"]\n",
    "    list_2 = globals()[f\"{last_name}_list\"]\n",
    "\n",
    "    #to uniform\n",
    "    list_1 = list_1[list_1.index.isin(list_2.index)]\n",
    "    list_2 = list_2[list_2.index.isin(list_1.index)]\n",
    "    hyper_params = parameters_for_hypergeometric(list_1, list_2)\n",
    "    df_cmap = build_map(*hyper_params)\n",
    "    df_cmap[df_cmap<3]=0\n",
    "    df_cmap = df_cmap.sort_values(by=[t for t in df_cmap.columns], ascending=False)\n",
    "    plot_map(df_cmap, first_name=first_name, last_name=last_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(\"hsbm\",\"tm\")\n",
    "run(\"hsbm\",\"lda\")\n",
    "run(\"hsbm\",\"wgcna\")\n",
    "run(\"tm\",\"lda\")\n",
    "run(\"tm\",\"wgcna\")\n",
    "run(\"lda\",\"wgcna\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"hsbm & tm %.3f \\\\\\\\ \\hline\"%v_measure_score(hsbm_list.reindex_like(tm_list), tm_list))\n",
    "print(\"hsbm & lda %.3f \\\\\\\\ \\hline\"%v_measure_score(hsbm_list.reindex_like(lda_list).dropna(), lda_list.reindex_like(hsbm_list).dropna()))\n",
    "print(\"hsbm & wgcna %.3f \\\\\\\\ \\hline\"%v_measure_score(hsbm_list.reindex_like(wgcna_list), wgcna_list))\n",
    "print(\"tm & lda %.3f \\\\\\\\ \\hline\"%v_measure_score(tm_list.reindex_like(lda_list).dropna(), lda_list.reindex_like(tm_list).dropna()))\n",
    "print(\"tm & wgcna %.3f \\\\\\\\ \\hline\"%v_measure_score(tm_list.reindex_like(wgcna_list).dropna(), wgcna_list.reindex_like(tm_list).dropna()))\n",
    "print(\"lda & wgcna %.3f \\\\\\\\ \\hline\"%v_measure_score(lda_list.reindex_like(wgcna_list).dropna(), wgcna_list.reindex_like(lda_list).dropna()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for g in hsbm_list[hsbm_list==\"Topic 1\"].index:\n",
    "    print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
